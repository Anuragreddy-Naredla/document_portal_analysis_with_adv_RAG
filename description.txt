1. create virtual environment.

    -> conda create -p env python=3.10 -y
    -> conda activate env
    -> To check type "pip list"

2. Create the github and commit the files.

    -> git init
    -> give commit and click on Publish Branch

3. To install the requirements.

    -> pip install -r requirements.txt

#### Min requirement for this project ####
1. LLM Model(GROQ[freely],openai[paid],gemini[15days free access], claude[paid], huggingface[freely], Ollama[local setup])
2. Embedding Model (openai, huggingface, gemini)
3. vectordatabase
    -> 3variants of database
        a. inmemory database
        b. ondisk database
        c. cloudbase database

### COMMANDS ###
1. pip list
2. pip install -e .
    -> It will create the document_portal_analysis_with_adv_RAG as the package and also we can publish to pypi 
3. pip list
    -> we can see the document_portal_analysis_with_adv_RAG as package under env which is virtual environment
4. pip install -r requirements.txt
    -> To Install all the libraries.

### API KEYS ###
1. Groq api key.
    -> Go to the groq website https://console.groq.com/keys
    -> Go to API keys tab
    -> Click on Create API Key and copy and paste and give in the .env file
        (GROQ_API_KEY="GIVE YOUR API KEY HERE")
        
2. Google API KEY
    -> Go to the google ai studio website and create the api key. https://aistudio.google.com/prompts/new_chat
    -> click on Create API key and copy and paste under the .env file as 
        (GOOGLE_API_KEY="GIVE YOUR API KEY HERE")

TO TEST THE UI FROM VSCODE:
1. Download "live server" extension from vscode.
2. Right click on "index.html" click on "Open with Live Server".



#WITH COMMAND
1. set LLM_PROVIDER=google
1. cd api/
2. uvicorn main:app --reload 
3. uvicorn api.main:app --port 8083 --reload[If we want to run from ROOT folder we can use this command,
                                            api->folder name, main->python filename,app->fastapi]
        (OR)
   uvicorn api.main:app --host 0.0.0.0 --port 8080 --reload



# FOR CREATING ANOTHER BRANCH AND SWITCH #####
    -> In master branch only we will deploy this app'n
1. git checkout -b dev (We will create a dev branch with this command)
2. git switch dev
3. git  switch master

#FOR CREATING THE DOCKER IMAGE IN LOCAL i.e, in "Docker Desktop app" Type below commands in CMD#
1. docker build -t document-portal-system-with-rag .
    -> -t which means tag, 
    -> .=>Where the dockerfile available
    -> document-portal-system-with-rag => name of the docker image
2. docker images
    -> We can see all the images which was build on docker.
3. docker run -d -p 8093:8080 --name doc-portal-app document-portal-system-with-rag
    -> -d=>detachmode which means in background everything will run
    -> -p=>publish
    -> 8093=>Port in local system
    -> 8080=>container port
    -> --name doc-portal-app =>name of my container.
    -> document-portal-system-with-rag=>This is the image name

4. To check write below commad in browser
    -> http://localhost:8093/


##### CONFIGURE THE BELOW SERVICES IN AWS #####

1. Configure "ECR"
    -> search for ECR and click on Elastic container Registry.
    -> Region should be "ap-southeast-2" under "sydney" which displayed on top right of ECR.[we can select any Region]
    -> click on "Create Repository".
    -> Give the name[documentportalsystem] which you have written in "aws.yaml" file under "ECR_REPOSITORY"
    -> open the "Image scanning settings - deprecated" then enable the "Scan on push".
    -> Finaly click on "create" button.
    -> copy the "Name" and "URI" and paste somewhere.
2. Configure "IAM USER"
    -> search for "IAM" then click on that service.
    -> select the "User" which is displayed on leftside under "Access Management"
    -> click on "User"
    -> click on "Create user"
    -> Give the User name.
    -> Then click on "Next".
    -> click on "Attach Policies directly".
    -> search the "AmazonEC2ContainerRegistryFullAccess" then click on checkbox
    -> search the "AmazonECS_FullAccess" then click on checkbox
    -> search the "AmazonS3FullAccess" then click on checkbox
    -> search the "SecretsManagerReadWrite" then click on checkbox.
    -> search the "CloudWatchLogsFullAccess" then click on checkbox
    -> click on "Next" then click on "Create user".
    -> After creating click on name then click on "Security credentials"
    -> copy the "ARN" under "Summary" which displayed on top left.
    -> Goto the "Security credentials" click on "Create access key" under "Access Keys". 
    -> select the "Command Line Interface(CLI)" then click on confirmation checkbox then click on "Next".
    -> Click on "Create access key" then copy the "Access key" and "Secret access key" or download the CSV file.
    -> To make the connection between Github and AWS we require these access keys.
    -> Finally click on "Done"
    -> After generating all the above credentials add these credentials to github to make the connection these secrets will be read in
       github workflows in aws.yaml file.
        -> open the Github click on "Settings"
        -> click on "Secrets and variables" then click on "Actions"
        -> click on "New repository secret".
        -> Give the name and secret access keys.
            a. Give this name "AWS_ACCESS_KEY_ID" and "GIVE THE access_key value" which is displayed on .json file which you have downloaded 
               above then click on "Add secret"
            b. Give this name "AWS_SECRET_ACCESS_KEY" and "GIVE THE SECRET ACCESS KEY value" which is displayed on .json file which you have 
               downloaded above then click on "Add secret"
        -> Do some changes in the code then push the code to github then CI/CD will be build with docker image then this docker image
           will be pushed to ECR Refresh the ECR page then we can see the docker image build id.
    -> open the tast_definition.json and give your "ID"(Which is displayed on AWS account top right) under "executionRoleArn"
    -> In task_defition.json give "URI" under "image"

3. Configure "ECS"
    -> Search for ECS then click on that
    -> Go to "Clusters" on top left then click on the "Create Cluster"
    -> Go to "aws.yaml" file and take out the "ECS_CLUSTER" name and give this name in ECS
    -> select the "AWS FARGATE(serverless)"
    -> click on "Create"
    -> click on the "Task definitions" which is displayed on top left 
    -> select the "Create new task definition with JSON" then copy the "task_defition.json" code and paste in AWS.
    -> click on "Create"
4. Configure "AWS SECRET MANAGER"
    -> search for "Secret manager"
    -> click on "Store a new secret"
    -> select the "other type of secret"
    -> Give the GROQ_API_KEY and GOOGLE_API_KEY under "key/value pairs"
    -> click on "Next"
    -> give "name" then click on Next again click on Next
    -> Finally click on "store"

################################################
##########ACCESSING THE APPLICATION ############
1. go to services of ECS in Clusters.
2. got to tasks then click on recent task.
3. under the "configuration" go to "Public IP"
4. click on "Open address" then write the port as 8080
    -> 3.104.78.140:8080



##### Steps for running the App over the ECS:#####


1. pull my latest entire code
1.1 you will updated githubaction/workflow folder
1.2 you will get updated utils/model_loader.py
2. AWS Account
3. AWS IAM User
3.1 fetch the credential from the IAM USER: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY
3.2 these credential keep inside your GitHub secretes
4. AWS Secrete Manager: keep your API keys over there
5. Setup your ECR
6. Create Cluster on your ECS
7. add the policy(incline_policy) either inside your IAM user or inside the role
7.1 these is a custom policy for giving correct permission between services 
7.2 check the code folder there i have given incline policy json file
7.3 there is two policy
7.4 first create first policy then create second policy with the appropriate given name and the exact json 
8. go inside the EC2 and add your inbould details
open EC2-> left hand side check with the security group-> click on security group id then add the inbound rule
TYPE Custom TCP TCP8080 ANYWHERE IPV4 0.0.0.0/0
9. for accessing the application 
ECS CLuster->Service->Task->PublicIP
if you are not able to get public IP there
then click on the ENI id there check with your public IPV4 Address

for executing the application this should be running on your browswer
http:/<your_public_ip>:8080

10 how to watch the logs
search for cloud watch->click on log groups --> check with your running task id --> then open the log for the same task id